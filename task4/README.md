# Окружение

* ОС - `6.1.71-1-MANJARO`.
* Процессор - `11th Gen Intel(R) Core(TM) i7-11800H @ 2.30GHz`.
* Размер `L1d` - `384 Kib`

# Эксперимент

## Описание

> Требовалось построить приближенное решение краевой задачи методом конечных элементов с кусочно-линейными базисными
> функциями.

> Для построения теоретической оценки сходимости алгоритма и самого алгоритма использовалось
> пособие [Методы вычислений, Хакимзянов, Черный](http://www.ict.nsc.ru/matmod/files/textbooks/KhakimzyanovCherny-2.pdf)

В качестве краевой задачи, для которой проводилась оценка сходимости, было взято уравнение (
_предложенное [@osogi](https://github.com/osogi)_) на отрезке $[0, \frac{16*\pi}{\sqrt{λ}}]$:

$$
y'' - λy = -2λ * sin(\sqrt{λ}*x)
$$

С граничными условиями:

* $y(0) = 0$
* $y(\frac{16*\pi}{\sqrt{λ}}) = 0$

> Явным решением уравнения является функция: $y(x) = sin(x*\sqrt{λ})$

> Для построения приближенного решения использовалась равномерная сетка.

> Эксперимент проводился на сетке, шаг которой в 10 раз меньше шага расчетной сетки.
---

## Теоритическое ожидание

Максимальная ошибка полученного приближения будет того же или меньшего порядка, что и величина $h^2$. Где $h^2$ - это
шаг расчетной сетки.

> Более точную оценку можно найти в главе 8.7
> пособия [Методы вычислений, Хакимзянов, Черный](http://www.ict.nsc.ru/matmod/files/textbooks/KhakimzyanovCherny-2.pdf)
---

## Результат

<table>
	<tbody>
		<tr>
			<td><b>λ</b></td>
			<td><b>Error</b></td>
			<td><b>h^2</b></td>
			<td><b>N</b></td>
		</tr>
		<tr>
			<td>1</td>
			<td>1.02</td>
			<td>31.19</td>
			<td>10</td>
		</tr>
		<tr>
			<td>1</td>
			<td>0.02</td>
			<td>0.3</td>
			<td>100</td>
		</tr>
		<tr>
			<td>1</td>
			<td>0.0002</td>
			<td>0.003</td>
			<td>1000</td>
		</tr>
		<tr>
			<td>1</td>
			<td>0.000012</td>
			<td>0.00003</td>
			<td>10000</td>
		</tr>
		<tr>
			<td>10</td>
			<td>1.02</td>
			<td>3.12</td>
			<td>10</td>
		</tr>
		<tr>
			<td>10</td>
			<td>0.02</td>
			<td>0.03</td>
			<td>100</td>
		</tr>
		<tr>
			<td>10</td>
			<td>0.0002</td>
			<td>0.0003</td>
			<td>1000</td>
		</tr>
		<tr>
			<td>10</td>
			<td>0.000012</td>
			<td>0.000003</td>
			<td>10000</td>
		</tr>
		<tr>
			<td>100</td>
			<td>1.02</td>
			<td>0.3</td>
			<td>10</td>
		</tr>
		<tr>
			<td>100</td>
			<td>0.02</td>
			<td>0.003</td>
			<td>100</td>
		</tr>
		<tr>
			<td>100</td>
			<td>0.0002</td>
			<td>0.00003</td>
			<td>1000</td>
		</tr>
		<tr>
			<td>1000</td>
			<td>1.02</td>
			<td>0.03</td>
			<td>10</td>
		</tr>
		<tr>
			<td>1000</td>
			<td>0.02</td>
			<td>0.0003</td>
			<td>100</td>
		</tr>
	</tbody>
</table>

> * **λ** - значение параметра
> * **Error** - макисмальная разность между ожидаемым значением и приближенным
> * **h^2** - шаг расчетной сетки в квадрате
> * **N** - количество узлов расчетной сетки

Из таблицы видно, что ожидаемая оценка выполняется.

> Так как максимальная ошибка (**Error**) не превосходит $O(h^2)$. Это означает, что для верхней границы оценки можно
> использовать $g(h) = h^2 * λ$. Тогда все ошибки будут ограничены этим значением.  
